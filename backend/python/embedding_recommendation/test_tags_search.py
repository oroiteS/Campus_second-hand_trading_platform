#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„æ ‡ç­¾æœç´¢æµ‹è¯•ç¨‹åº
ç”¨äºæµ‹è¯•ChromaDBå‘é‡å­˜å‚¨å’Œæœç´¢åŠŸèƒ½
"""

import os
import chromadb
from dotenv import load_dotenv
import requests
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity as sklearn_cosine_similarity # Renamed to avoid conflict
from collections import Counter
from dotenv import load_dotenv
# LM Studio API Configuration
LM_STUDIO_API_URL = "http://127.0.0.1:1234/v1/embeddings"
LM_STUDIO_MODEL_NAME = "text-embedding-qwen3-reranker-4b"

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class OllamaEmbeddingFunction:
    def __init__(self, api_base, model_name):
        self.api_base = api_base
        self.model_name = model_name

    def __call__(self, input):
        if not input:
            return []
        
        # ç¡®ä¿inputæ˜¯åˆ—è¡¨æ ¼å¼
        if isinstance(input, str):
            input = [input]
        
        texts = input
        
        embeddings = []
        
        # é€ä¸ªå¤„ç†æ¯ä¸ªæ–‡æœ¬
        for text in texts:
            headers = {"Content-Type": "application/json"}
            payload = {"prompt": text, "model": self.model_name}
            
            try:
                response = requests.post(f"{self.api_base}/embeddings", headers=headers, json=payload)
                response.raise_for_status()
                
                json_response = response.json()
                if 'embedding' in json_response:
                    embeddings.append(json_response['embedding'])
                else:
                    print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°åµŒå…¥æ•°æ®ï¼Œå“åº”: {json_response}")
                    # è¿”å›ä¸€ä¸ªé»˜è®¤çš„åµŒå…¥å‘é‡ï¼ˆå…¨é›¶å‘é‡ï¼‰
                    embeddings.append([0.0] * 384)  # å‡è®¾384ç»´
            except Exception as e:
                print(f"è°ƒç”¨Ollama APIå¤±è´¥: {e}")
                # è¿”å›ä¸€ä¸ªé»˜è®¤çš„åµŒå…¥å‘é‡
                embeddings.append([0.0] * 384)
        
        return embeddings

def test_search():
    """æµ‹è¯•æœç´¢åŠŸèƒ½ï¼ˆå¸¦é‡æ’æ¨¡å‹ï¼‰"""
    print("=== å¼€å§‹æµ‹è¯•æ ‡ç­¾æœç´¢åŠŸèƒ½ï¼ˆä½¿ç”¨é‡æ’æ¨¡å‹ï¼‰===")
    
    # åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯
    client = chromadb.PersistentClient(path="tags_vector_db/")
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    api_base = os.getenv('OPENAI_API_BASE', 'http://localhost:11434/api')
    model_name = os.getenv('OPENAI_EMBEDDING_MODEL_NAME', 'qwen3-embedding-0.6b:latest')
    
    # åˆ›å»ºåµŒå…¥å‡½æ•°
    embedding_func = OllamaEmbeddingFunction(api_base, model_name)
    # LM Studio Reranker (via embeddings) is used directly in the search loop
    
    try:
        # è·å–å·²å­˜åœ¨çš„é›†åˆ
        collection = client.get_collection(name="tags_collection", embedding_function=embedding_func)
        print(f"æˆåŠŸè¿æ¥åˆ°é›†åˆï¼ŒåŒ…å« {collection.count()} ä¸ªæ ‡ç­¾")
        
        # æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
        test_queries = [
            "ç”µè„‘",
            "æ‰‹æœº",
            "æ•°å­¦",
            "ä¹¦ç±",
            "è¿åŠ¨",
            "éŸ³ä¹",
            "æ¸¸æˆ",
            "å­¦ä¹ "
        ]
        
        print("\n=== å¼€å§‹æœç´¢æµ‹è¯• ===")
        for query in test_queries:
            print(f"\næœç´¢æŸ¥è¯¢: '{query}'")
            try:
                # æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢ï¼ˆè·å–æ›´å¤šç»“æœç”¨äºé‡æ’ï¼‰
                results = collection.query(
                    query_texts=[query],
                    n_results=10  # è·å–æ›´å¤šç»“æœç”¨äºé‡æ’
                )
                
                if results['documents'] and results['documents'][0]:
                    print("\nåŸå§‹æœç´¢ç»“æœ:")
                    for i, (doc, distance) in enumerate(zip(results['documents'][0][:3], results['distances'][0][:3])):
                        print(f"  {i+1}. {doc} (åµŒå…¥ç›¸ä¼¼åº¦: {1-distance:.3f})")
                    
                    # ä½¿ç”¨ LM Studio Embeddings API è¿›è¡Œé‡æ’
                    docs_to_rerank = results['documents'][0]
                    query_embedding_for_rerank = get_lm_studio_embedding(query, LM_STUDIO_MODEL_NAME, LM_STUDIO_API_URL)
                    rerank_scores = []
                    if query_embedding_for_rerank:
                        for doc_text in docs_to_rerank:
                            doc_embedding_for_rerank = get_lm_studio_embedding(doc_text, LM_STUDIO_MODEL_NAME, LM_STUDIO_API_URL)
                            if doc_embedding_for_rerank:
                                score = cosine_similarity_local(query_embedding_for_rerank, doc_embedding_for_rerank)
                                rerank_scores.append(score)
                            else:
                                rerank_scores.append(0.0) # Assign low score if embedding fails
                    else:
                        print("  æ— æ³•è·å–æŸ¥è¯¢çš„ LM Studio åµŒå…¥ï¼Œè·³è¿‡é‡æ’ã€‚")
                        rerank_scores = [0.0] * len(docs_to_rerank) # Assign all zero if query embedding fails
                    
                    if rerank_scores:
                        # å°†åˆ†æ•°ä¸æ–‡æ¡£å…³è”å¹¶æ’åº
                        reranked_items = []
                        for doc, score, original_distance in zip(docs_to_rerank, rerank_scores, results['distances'][0]):
                            reranked_items.append({
                                'document': doc,
                                'original_embedding_similarity': 1 - original_distance, # åŸå§‹åµŒå…¥ç›¸ä¼¼åº¦ (æ¥è‡ªChromaDB)
                                'rerank_score': score, # æ–°çš„é‡æ’åˆ†æ•° (æ¥è‡ªLM Studio)
                                # 'final_score' will be replaced by RRF score later
                                'doc_id': doc # Keep track of document for RRF
                            })
                        
                        # Calculate RRF scores
                        # First, get ranks for original similarity
                        original_ranked_docs = sorted(reranked_items, key=lambda x: x['original_embedding_similarity'], reverse=True)
                        original_ranks = {item['doc_id']: i + 1 for i, item in enumerate(original_ranked_docs)}

                        # Second, get ranks for rerank scores
                        rerank_model_ranked_docs = sorted(reranked_items, key=lambda x: x['rerank_score'], reverse=True)
                        rerank_model_ranks = {item['doc_id']: i + 1 for i, item in enumerate(rerank_model_ranked_docs)}

                        k_rrf = 20 # RRF k parameter
                        for item in reranked_items:
                            rank1 = original_ranks.get(item['doc_id'], len(reranked_items) + 1) # Default to a large rank if not found
                            rank2 = rerank_model_ranks.get(item['doc_id'], len(reranked_items) + 1)
                            item['rrf_score'] = (1 / (k_rrf + rank1)) + (1 / (k_rrf + rank2))
                        
                        # Sort by RRF score
                        reranked_items.sort(key=lambda x: x['rrf_score'], reverse=True)
                        
                        print("\né‡æ’åç»“æœ (ä½¿ç”¨ RRF èåˆ):")
                        for i, item in enumerate(reranked_items[:5]):
                            print(f"  {i+1}. {item['document']}")
                            print(f"     åŸå§‹åµŒå…¥ç›¸ä¼¼åº¦: {item['original_embedding_similarity']:.3f} (æ’å: {original_ranks.get(item['doc_id'], 'N/A')})")
                            print(f"     é‡æ’æ¨¡å‹åˆ†æ•°: {item['rerank_score']:.3f} (æ’å: {rerank_model_ranks.get(item['doc_id'], 'N/A')})")
                            print(f"     RRF èåˆå¾—åˆ†: {item['rrf_score']:.6f}")
                            print()
                    else:
                        print("  é‡æ’å¤±è´¥æˆ–æ²¡æœ‰è¿”å›åˆ†æ•°ã€‚")
                else:
                    print("  æœªæ‰¾åˆ°ç›¸ä¼¼æ ‡ç­¾")
                    
            except Exception as e:
                print(f"  æœç´¢å¤±è´¥: {e}")
        
        print("\n=== æµ‹è¯•å®Œæˆ ===")
        
    except Exception as e:
        print(f"æ— æ³•è¿æ¥åˆ°é›†åˆ: {e}")
        print("è¯·å…ˆè¿è¡Œ simple_tags_vector.py æ¥åˆ›å»ºå‘é‡æ•°æ®åº“")

def show_all_tags():
    """æ˜¾ç¤ºæ‰€æœ‰å­˜å‚¨çš„æ ‡ç­¾"""
    print("\n=== æ˜¾ç¤ºæ‰€æœ‰å­˜å‚¨çš„æ ‡ç­¾ ===")
    
    client = chromadb.PersistentClient(path="tags_vector_db/")
    
    try:
        collection = client.get_collection(name="tags_collection")
        
        # è·å–æ‰€æœ‰æ–‡æ¡£
        all_docs = collection.get()
        
        if all_docs['documents']:
            print(f"æ€»å…±å­˜å‚¨äº† {len(all_docs['documents'])} ä¸ªæ ‡ç­¾:")
            for i, doc in enumerate(all_docs['documents'][:20]):  # åªæ˜¾ç¤ºå‰20ä¸ª
                print(f"  {i+1}. {doc}")
            
            if len(all_docs['documents']) > 20:
                print(f"  ... è¿˜æœ‰ {len(all_docs['documents']) - 20} ä¸ªæ ‡ç­¾")
        else:
            print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ ‡ç­¾")
            
    except Exception as e:
        print(f"æ— æ³•è·å–æ ‡ç­¾åˆ—è¡¨: {e}")

def compare_search_methods(query):
    """æ¯”è¾ƒåŸå§‹æœç´¢å’Œé‡æ’æœç´¢çš„æ•ˆæœ"""
    print(f"\n=== æœç´¢æ–¹æ³•å¯¹æ¯”: '{query}' ===")
    
    client = chromadb.PersistentClient(path="tags_vector_db/")
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    api_base = os.getenv('OPENAI_API_BASE', 'http://localhost:11434/api')
    model_name = os.getenv('OPENAI_EMBEDDING_MODEL_NAME', 'qwen3-embedding-0.6b:latest')
    
    # åˆ›å»ºåµŒå…¥å‡½æ•°å’Œé‡æ’æ¨¡å‹
    embedding_func = OllamaEmbeddingFunction(api_base, model_name)
    try:
        reranker = RerankerModel(model_dir='./model/Qwen3-4B-Base')
    except FileNotFoundError as e:
        print(f"æ— æ³•åŠ è½½é‡æ’æ¨¡å‹: {e}")
        print("è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠæ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚")
        return
    except Exception as e:
        print(f"åŠ è½½é‡æ’æ¨¡å‹æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return
    
    try:
        collection = client.get_collection(name="tags_collection", embedding_function=embedding_func)
        results = collection.query(
            query_texts=[query],
            n_results=10
        )
        
        if results['documents'] and results['documents'][0]:
            print("\nğŸ“Š åŸå§‹åµŒå…¥æœç´¢ç»“æœ:")
            for i, (doc, distance) in enumerate(zip(results['documents'][0][:5], results['distances'][0][:5])):
                print(f"  {i+1}. {doc} (ç›¸ä¼¼åº¦: {1-distance:.3f})")
            
            # ä½¿ç”¨ LM Studio Embeddings API è¿›è¡Œé‡æ’
            docs_to_rerank = results['documents'][0]
            query_embedding_for_rerank = get_lm_studio_embedding(query, LM_STUDIO_MODEL_NAME, LM_STUDIO_API_URL)
            rerank_scores = []
            if query_embedding_for_rerank:
                for doc_text in docs_to_rerank:
                    doc_embedding_for_rerank = get_lm_studio_embedding(doc_text, LM_STUDIO_MODEL_NAME, LM_STUDIO_API_URL)
                    if doc_embedding_for_rerank:
                        score = cosine_similarity_local(query_embedding_for_rerank, doc_embedding_for_rerank)
                        rerank_scores.append(score)
                    else:
                        rerank_scores.append(0.0) # Assign low score if embedding fails
            else:
                print("  æ— æ³•è·å–æŸ¥è¯¢çš„ LM Studio åµŒå…¥ï¼Œè·³è¿‡é‡æ’ã€‚")
                rerank_scores = [0.0] * len(docs_to_rerank)

            if rerank_scores:
                reranked_items = []
                for doc, score, original_distance in zip(docs_to_rerank, rerank_scores, results['distances'][0]):
                    original_sim = 1 - original_distance
                    reranked_items.append({
                        'document': doc,
                        'original_embedding_similarity': original_sim, # åŸå§‹åµŒå…¥ç›¸ä¼¼åº¦ (æ¥è‡ªChromaDB)
                        'rerank_score': score, # æ–°çš„é‡æ’åˆ†æ•° (æ¥è‡ªLM Studio)
                        # 'final_score' will be replaced by RRF score later
                        'doc_id': doc # Keep track of document for RRF
                    })
                # Calculate RRF scores
                original_ranked_docs_comp = sorted(reranked_items, key=lambda x: x['original_embedding_similarity'], reverse=True)
                original_ranks_comp = {item['doc_id']: i + 1 for i, item in enumerate(original_ranked_docs_comp)}

                rerank_model_ranked_docs_comp = sorted(reranked_items, key=lambda x: x['rerank_score'], reverse=True)
                rerank_model_ranks_comp = {item['doc_id']: i + 1 for i, item in enumerate(rerank_model_ranked_docs_comp)}

                k_rrf = 20 # RRF k parameter
                for item in reranked_items:
                    rank1_comp = original_ranks_comp.get(item['doc_id'], len(reranked_items) + 1)
                    rank2_comp = rerank_model_ranks_comp.get(item['doc_id'], len(reranked_items) + 1)
                    item['rrf_score'] = (1 / (k_rrf + rank1_comp)) + (1 / (k_rrf + rank2_comp))
                
                reranked_items.sort(key=lambda x: x['rrf_score'], reverse=True)

                print("\nğŸ¯ RRF èåˆç»“æœ:")
                for i, item in enumerate(reranked_items[:5]):
                    print(f"  {i+1}. {item['document']}")
                    print(f"     åŸå§‹åµŒå…¥ç›¸ä¼¼åº¦: {item['original_embedding_similarity']:.3f} (æ’å: {original_ranks_comp.get(item['doc_id'], 'N/A')})")
                    print(f"     é‡æ’æ¨¡å‹åˆ†æ•°: {item['rerank_score']:.3f} (æ’å: {rerank_model_ranks_comp.get(item['doc_id'], 'N/A')})")
                    print(f"     RRF èåˆå¾—åˆ†: {item['rrf_score']:.6f}")
            else:
                print("  é‡æ’å¤±è´¥æˆ–æ²¡æœ‰è¿”å›åˆ†æ•°ã€‚")
        else:
            print("  æœªæ‰¾åˆ°ç›¸ä¼¼æ ‡ç­¾")
            
    except Exception as e:
        print(f"æœç´¢å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ChromaDB æ ‡ç­¾æœç´¢æµ‹è¯•ç¨‹åº (å¸¦é‡æ’æ¨¡å‹)")
    print("=" * 50)
    
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. æµ‹è¯•æœç´¢åŠŸèƒ½ (ä½¿ç”¨é‡æ’æ¨¡å‹)")
        print("2. æ˜¾ç¤ºæ‰€æœ‰æ ‡ç­¾")
        print("3. è‡ªå®šä¹‰æœç´¢ (å¯¹æ¯”é‡æ’æ•ˆæœ)")
        print("4. æœç´¢æ–¹æ³•æ•ˆæœå¯¹æ¯”")
        print("5. é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-5): ").strip()
        
        if choice == '1':
            test_search()
        elif choice == '2':
            show_all_tags()
        elif choice == '3':
            query = input("è¯·è¾“å…¥æœç´¢å…³é”®è¯: ").strip()
            if query:
                print(f"\næœç´¢æŸ¥è¯¢: '{query}'")
                client = chromadb.PersistentClient(path="tags_vector_db/")
                
                # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
                api_base = os.getenv('OPENAI_API_BASE', 'http://localhost:11434/api')
                model_name = os.getenv('OPENAI_EMBEDDING_MODEL_NAME', 'qwen3-embedding-0.6b:latest')
                
                # åˆ›å»ºåµŒå…¥å‡½æ•°
                embedding_func = OllamaEmbeddingFunction(api_base, model_name)
                # LM Studio Reranker (via embeddings) is used directly in the search loop
                
                try:
                    collection = client.get_collection(name="tags_collection", embedding_function=embedding_func)
                    results = collection.query(
                        query_texts=[query],
                        n_results=15
                    )
                    
                    if results['documents'] and results['documents'][0]:
                        print("\n=== åŸå§‹æœç´¢ç»“æœ ===")
                        for i, (doc, distance) in enumerate(zip(results['documents'][0][:8], results['distances'][0][:8])):
                            print(f"  {i+1}. {doc} (åµŒå…¥ç›¸ä¼¼åº¦: {1-distance:.3f})")
                        
                        # ä½¿ç”¨ LM Studio Embeddings API è¿›è¡Œé‡æ’
                        docs_to_rerank = results['documents'][0]
                        query_embedding_for_rerank = get_lm_studio_embedding(query, LM_STUDIO_MODEL_NAME, LM_STUDIO_API_URL)
                        rerank_scores = []
                        if query_embedding_for_rerank:
                            for doc_text in docs_to_rerank:
                                doc_embedding_for_rerank = get_lm_studio_embedding(doc_text, LM_STUDIO_MODEL_NAME, LM_STUDIO_API_URL)
                                if doc_embedding_for_rerank:
                                    score = cosine_similarity_local(query_embedding_for_rerank, doc_embedding_for_rerank)
                                    rerank_scores.append(score)
                                else:
                                    rerank_scores.append(0.0) # Assign low score if embedding fails
                        else:
                            print("  æ— æ³•è·å–æŸ¥è¯¢çš„ LM Studio åµŒå…¥ï¼Œè·³è¿‡é‡æ’ã€‚")
                            rerank_scores = [0.0] * len(docs_to_rerank) # Assign all zero if query embedding fails


                        if rerank_scores:
                            reranked_items = []
                            for doc, score, original_distance in zip(docs_to_rerank, rerank_scores, results['distances'][0]):
                                reranked_items.append({
                                    'document': doc,
                                    'original_embedding_similarity': 1 - original_distance, # åŸå§‹åµŒå…¥ç›¸ä¼¼åº¦ (æ¥è‡ªChromaDB)
                                    'rerank_score': score, # æ–°çš„é‡æ’åˆ†æ•° (æ¥è‡ªLM Studio)
                                    # 'final_score' will be replaced by RRF score later
                                    'doc_id': doc # Keep track of document for RRF
                                })
                            # Calculate RRF scores
                            original_ranked_docs_main = sorted(reranked_items, key=lambda x: x['original_embedding_similarity'], reverse=True)
                            original_ranks_main = {item['doc_id']: i + 1 for i, item in enumerate(original_ranked_docs_main)}

                            rerank_model_ranked_docs_main = sorted(reranked_items, key=lambda x: x['rerank_score'], reverse=True)
                            rerank_model_ranks_main = {item['doc_id']: i + 1 for i, item in enumerate(rerank_model_ranked_docs_main)}

                            k_rrf = 20 # RRF k parameter
                            for item in reranked_items:
                                rank1_main = original_ranks_main.get(item['doc_id'], len(reranked_items) + 1)
                                rank2_main = rerank_model_ranks_main.get(item['doc_id'], len(reranked_items) + 1)
                                item['rrf_score'] = (1 / (k_rrf + rank1_main)) + (1 / (k_rrf + rank2_main))
                            
                            reranked_items.sort(key=lambda x: x['rrf_score'], reverse=True)

                            print("\n=== é‡æ’åç»“æœ (ä½¿ç”¨ RRF èåˆ) ===")
                            for i, item in enumerate(reranked_items[:8]):
                                print(f"  {i+1}. {item['document']}")
                                print(f"     åŸå§‹åµŒå…¥ç›¸ä¼¼åº¦: {item['original_embedding_similarity']:.3f} (æ’å: {original_ranks_main.get(item['doc_id'], 'N/A')})")
                                print(f"     é‡æ’æ¨¡å‹åˆ†æ•°: {item['rerank_score']:.3f} (æ’å: {rerank_model_ranks_main.get(item['doc_id'], 'N/A')})")
                                print(f"     RRF èåˆå¾—åˆ†: {item['rrf_score']:.6f}")
                                if i < 7:
                                    print()
                        else:
                            print("  é‡æ’å¤±è´¥æˆ–æ²¡æœ‰è¿”å›åˆ†æ•°ã€‚")
                    else:
                        print("  æœªæ‰¾åˆ°ç›¸ä¼¼æ ‡ç­¾")
                except Exception as e:
                    print(f"æœç´¢å¤±è´¥: {e}")
        elif choice == '4':
            query = input("è¯·è¾“å…¥è¦å¯¹æ¯”çš„æœç´¢å…³é”®è¯: ").strip()
            if query:
                compare_search_methods(query)
        elif choice == '5':
            print("é€€å‡ºç¨‹åº")
            break
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

def get_lm_studio_embedding(text: str, model_name: str, api_url: str):
    """Fetches an embedding for the given text using the LM Studio API."""
    headers = {"Content-Type": "application/json"}
    payload = {
        "input": text,
        "model": model_name
    }
    try:
        response = requests.post(api_url, headers=headers, json=payload)
        response.raise_for_status()
        json_response = response.json()
        if json_response.get("data") and isinstance(json_response["data"], list) and len(json_response["data"]) > 0:
            embedding_data = json_response["data"][0]
            if isinstance(embedding_data, dict) and "embedding" in embedding_data:
                return embedding_data["embedding"]
    except requests.exceptions.RequestException as e:
        print(f"Error calling LM Studio API for embedding: {e}")
    except Exception as e:
        print(f"An unexpected error occurred during LM Studio embedding: {e}")
    return None

def cosine_similarity_local(vec1, vec2):
    """Computes the cosine similarity between two vectors."""
    if vec1 is None or vec2 is None:
        return 0.0
    vec1 = np.array(vec1)
    vec2 = np.array(vec2)
    if vec1.shape != vec2.shape:
        return 0.0
    if np.linalg.norm(vec1) == 0 or np.linalg.norm(vec2) == 0:
        return 0.0
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

if __name__ == "__main__":
    main()